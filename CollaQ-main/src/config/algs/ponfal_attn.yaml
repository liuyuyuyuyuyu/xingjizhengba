# --- QMIX specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000

runner: "episode"

buffer_size: 5000

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "ponfal_learner"
double_q: True
mixer: "qmix"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64
regulization: "all_"

name: "ponfal_attn"

# --- Agent parameters ---
agent: "rnn_interactive_attnv1" # Default rnn agent
single_model_name: "./alone_models/"
pretrained: False
attn_embed_dim: 32
attn_layers: 1

# --- pymarl options ---
mac: "basic_mac_interactive_regv1" # Basic controller
minus_target_update_interval: 200

# --- QTRAN ---

# use epsilon greedy action selector
qtran_arch: "qtran_paper"

opt_loss: 1
nopt_min_loss: 0.1
alpha: 0.01

network_size: small